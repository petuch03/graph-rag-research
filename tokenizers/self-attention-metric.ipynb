{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/petuch03/graph-rag-research/blob/master/tokenizers/self-attention-visualization.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aeed29255010eb54"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "data": {
      "text/plain": "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "af437e64d77a4ddeb59f1ea9f050901c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from types import SimpleNamespace\n",
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T16:13:30.792472Z",
     "start_time": "2024-04-01T16:13:29.138389Z"
    }
   },
   "id": "e329b305d4472d0"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "667bc78044dc4d1994847004cb1712b8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load model and retrieve attention weights\n",
    "\n",
    "from bertviz import model_view\n",
    "from transformers import GemmaTokenizer, GemmaForCausalLM\n",
    "\n",
    "# configuration = GemmaConfig()\n",
    "model_version = 'google/gemma-2b-it'\n",
    "\n",
    "model = GemmaForCausalLM.from_pretrained(model_version, output_attentions=True)\n",
    "tokenizer = GemmaTokenizer.from_pretrained(model_version)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T16:13:51.935730Z",
     "start_time": "2024-04-01T16:13:30.798491Z"
    }
   },
   "id": "88bc75601c78acd9"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Bob', '▁sent', '▁Alice', '▁a', '▁message', '▁about', '▁apples', '.']\n",
      "['B', 'o', 'b', '▁s', 'en', 't', '▁Al', 'ice', '▁', 'a', '▁mes', 'sage', '▁ab', 'out', '▁ap', 'ple', 's', '.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GemmaModel is using GemmaSdpaAttention, but `torch.nn.functional.scaled_dot_product_attention` does not support `output_attentions=True`. Falling back to the manual attention implementation, but specifying the manual implementation will be required from Transformers version v5.0.0 onwards. This warning can be removed using the argument `attn_implementation=\"eager\"` when loading the model.\n"
     ]
    }
   ],
   "source": [
    "from sub_word_tokenization import tokenize_custom\n",
    "\n",
    "input_text = 'Bob sent Alice a message about apples.'\n",
    "comparison_pair = tokenize_custom(tokenizer, \"tokenizer.json\", \"Bob sent Alice a message about apples.\")\n",
    "print(comparison_pair.default_tokens)\n",
    "print(comparison_pair.sub_word_tokens)\n",
    "\n",
    "\n",
    "def compute_attention_pipeline(tokenizer, input_tokens) -> SimpleNamespace:\n",
    "    inputs = tokenizer.encode(input_tokens, return_tensors='pt')\n",
    "    # tokens = tokenizer.convert_ids_to_tokens(inputs[0])\n",
    "    outputs = model(inputs)\n",
    "    attention = torch.stack(outputs[-1], dim=0)\n",
    "    return SimpleNamespace(attention=attention, full_outputs=outputs)\n",
    "\n",
    "\n",
    "default_model_output = compute_attention_pipeline(tokenizer, comparison_pair.default_tokens)\n",
    "sub_word_model_output = compute_attention_pipeline(tokenizer, comparison_pair.sub_word_tokens)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T16:14:53.648965Z",
     "start_time": "2024-04-01T16:13:51.943236Z"
    }
   },
   "id": "2ff69243ad4ad553"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold-based Noise Metric - Source: tensor([0.8889, 0.7878, 0.7160, 0.6628, 0.6265, 0.5586, 0.5116, 0.5239, 0.4282]), Source mean: 0.6338306069374084\n",
      "Target: tensor([0.0293, 0.4660, 0.5278, 0.6073, 0.6852, 0.7515, 0.8333, 0.8750, 0.9290])Target mean: 0.6338306069374084\n",
      "Entropy-based Noise Metric: 2.1522600650787354\n",
      "Threshold-based Noise Metric - Source: tensor([0.9474, 0.9050, 0.8852, 0.8578, 0.8209, 0.8056, 0.7957, 0.7482, 0.7569,\n",
      "        0.7515, 0.7109, 0.7105, 0.7105, 0.6860, 0.6996, 0.6784, 0.7061, 0.6849,\n",
      "        0.6140]), Source mean: 0.7618498802185059\n",
      "Target: tensor([0.0523, 0.6583, 0.6981, 0.6528, 0.6857, 0.7482, 0.7460, 0.7485, 0.7379,\n",
      "        0.7778, 0.7865, 0.8527, 0.8198, 0.8706, 0.8757, 0.9097, 0.9243, 0.9565,\n",
      "        0.9737])Target mean: 0.7618498802185059\n",
      "Entropy-based Noise Metric: 2.921490430831909\n"
     ]
    }
   ],
   "source": [
    "from sub_word_metrics import *\n",
    "\n",
    "show_all_metrics(default_model_output.attention, threshold=0.02)\n",
    "show_all_metrics(sub_word_model_output.attention, threshold=0.02)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T16:14:55.056901Z",
     "start_time": "2024-04-01T16:14:53.664539Z"
    }
   },
   "id": "a1132c88c44cf164"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "['▁Bob']"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = default_model_output.full_outputs.logits\n",
    "predicted_token_id = logits[:, -1, :].argmax(dim=-1)\n",
    "\n",
    "# Convert the predicted token ID to a token\n",
    "predicted_token = tokenizer.convert_ids_to_tokens(predicted_token_id)\n",
    "predicted_token"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T12:46:31.718709Z",
     "start_time": "2024-04-01T12:46:31.690080Z"
    }
   },
   "id": "72f67241db0b82f1"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "def generate_sequence_from_tokens(tokenizer, input_tokens, max_length=50, num_return_sequences=1):\n",
    "    inputs = tokenizer.encode(input_tokens, return_tensors='pt')\n",
    "    generated_sequences = model.generate(inputs, max_length=max_length, num_return_sequences=num_return_sequences)\n",
    "    generated_text = [tokenizer.decode(generated_sequence, skip_special_tokens=True) for generated_sequence in\n",
    "                      generated_sequences]\n",
    "\n",
    "    # Print the generated text\n",
    "    for text in generated_text:\n",
    "        print(text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T12:59:24.141219Z",
     "start_time": "2024-04-01T12:59:24.130397Z"
    }
   },
   "id": "158faf2850e21b9f"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bob sent Alice a message about apples. Bob sent Alice a message about apples, but it was not the same message as the one he sent her. What happened?\n",
      "\n",
      "Bob sent Alice a message about apples, but it was not the same message\n"
     ]
    }
   ],
   "source": [
    "generate_sequence_from_tokens(tokenizer, comparison_pair.default_tokens)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T13:02:53.783844Z",
     "start_time": "2024-04-01T12:59:25.476397Z"
    }
   },
   "id": "88a0b54bf5b41ce"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bob sent Alice a message about apples.\n",
      "\n",
      "Sure, here's the message about apples:\n",
      "\n",
      "\"Apples are a delicious fruit that is enjoyed by people of all ages. They are a good\n"
     ]
    }
   ],
   "source": [
    "generate_sequence_from_tokens(tokenizer, comparison_pair.sub_word_tokens)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T13:05:44.853141Z",
     "start_time": "2024-04-01T13:02:52.242264Z"
    }
   },
   "id": "8011a6abd2354935"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def process_batch(batch, tokenizer=tokenizer, tokenizer_config: str = \"tokenizer.json\", threshold: float = 0.01):\n",
    "    batch_result = torch.empty(len(batch), 2, 2)\n",
    "    for idx, input_sequence in enumerate(batch):\n",
    "        comparison_pair = tokenize_custom(tokenizer, tokenizer_config, input_sequence)\n",
    "        \n",
    "        default_model_attention = compute_attention_pipeline(tokenizer, comparison_pair.default_tokens).attention\n",
    "        sub_word_model_attention = compute_attention_pipeline(tokenizer, comparison_pair.sub_word_tokens).attention\n",
    "        \n",
    "        default_threshold_metric = threshold_noise_metric(default_model_attention, 0.01)\n",
    "        default_entropy_metric = entropy_based_noise_metric(default_model_attention)\n",
    "        batch_result[idx][0][0] = default_threshold_metric.source_noise_percentage_over_tokens\n",
    "        batch_result[idx][0][1] = default_entropy_metric\n",
    "        \n",
    "        sub_word_threshold_metric = threshold_noise_metric(sub_word_model_attention, 0.01)\n",
    "        sub_word_entropy_metric = entropy_based_noise_metric(sub_word_model_attention)\n",
    "        batch_result[idx][1][0] = sub_word_threshold_metric.source_noise_percentage_over_tokens\n",
    "        batch_result[idx][1][1] = sub_word_entropy_metric\n",
    "        \n",
    "    return batch_result\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T16:16:33.823823Z",
     "start_time": "2024-04-01T16:16:33.735547Z"
    }
   },
   "id": "92d7516d323a5107"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "input_sequences = [\"Bob sent Alice a message about apples.\", \"Cat didn't cross the street because it was tired.\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T16:16:33.827985Z",
     "start_time": "2024-04-01T16:16:33.809408Z"
    }
   },
   "id": "fec6135a83a6ac48"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "batch_result = process_batch(input_sequences, tokenizer, \"tokenizer.json\", 0.02)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T16:17:29.961190Z",
     "start_time": "2024-04-01T16:16:35.080721Z"
    }
   },
   "id": "f1611ca0116de68f"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[0.5814, 2.1523],\n         [0.6891, 2.9215]],\n\n        [[0.6385, 2.5323],\n         [0.7214, 3.2424]]])"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_result"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T16:17:29.968695Z",
     "start_time": "2024-04-01T16:17:29.958099Z"
    }
   },
   "id": "3cf66c1908151330"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "d1ee7ba5e3dfea34"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
